{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (7.1.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de conexão ao banco de dados\n",
    "db_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"telegram2\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Reve1945\"\n",
    "}\n",
    "\n",
    "url_pattern = r'(https?://\\S+)'\n",
    "\n",
    "built_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de mensagens já capturadas: 103555\n",
      "Número de mensagens já capturadas: 209345\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Conectando ao banco de dados\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "\n",
    "    # Criando um cursor\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Exemplo de consulta SQL com paginação\n",
    "    page_size = 100000  # Defina o tamanho da página desejado\n",
    "    offset = 0\n",
    "\n",
    "    total_messages_captured = 0  # Variável para contagem de mensagens capturadas\n",
    "\n",
    "    while True:\n",
    "        cursor.execute(\"SELECT * FROM messages_order_by_channel_utc LIMIT %s OFFSET %s\", (page_size, offset))\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        # Crie uma lista para armazenar as linhas capturadas na página atual\n",
    "        new_rows = []\n",
    "\n",
    "        for row in results:\n",
    "            if re.findall(url_pattern, row[3]):\n",
    "                # Adicione a linha capturada à lista de linhas da página atual\n",
    "                new_rows.append([row[2], row[3], row[4]])\n",
    "\n",
    "                # Calcule as faixas de tempo para considerar\n",
    "                start_time = row[4] - timedelta(minutes = 1)\n",
    "                end_time = row[4] + timedelta(minutes = 3)\n",
    "    \n",
    "                for i in range(results.index(row) - 1, -1, -1):\n",
    "                    if row[2] == results[i][2] and start_time <= results[i][4]:\n",
    "                        new_rows.append([results[i][2], results[i][3], results[i][4]])\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                for i in range(results.index(row) + 1, len(results)):\n",
    "                    if row[2] == results[i][2] and results[i][4] <= end_time:\n",
    "                        new_rows.append([results[i][2], results[i][3], results[i][4]])\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        # Atualize a contagem de mensagens capturadas\n",
    "        total_messages_captured += len(new_rows)\n",
    "        print(f\"Número de mensagens já capturadas: {total_messages_captured}\")\n",
    "\n",
    "        # Crie um DataFrame a partir da lista de linhas da página atual\n",
    "        df = pd.DataFrame(new_rows, columns = [\"channel_id\", \"message_data\", \"message_utc\"])\n",
    "        # Remova as duplicatas do DataFrame, se necessário\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        built_df = pd.concat([built_df, df], axis = 0)\n",
    "        \n",
    "        offset += page_size\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print('Fim da construção do dataframe.')\n",
    "\n",
    "    # Fechando o cursor\n",
    "    cursor.close()\n",
    "\n",
    "    # Fechando a conexão\n",
    "    conn.close()\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Erro na construção do dataframe:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>message_data</th>\n",
       "      <th>message_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1001230603327</td>\n",
       "      <td>https://www.drugs.com/drug-interactions/sars-c...</td>\n",
       "      <td>2021-10-12 16:02:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1001230603327</td>\n",
       "      <td>https://twitter.com/drobertalacerda/status/144...</td>\n",
       "      <td>2021-10-12 16:14:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1001230603327</td>\n",
       "      <td>IMUNIDADE NATURAL: \\n\\nCientistas identificam ...</td>\n",
       "      <td>2021-10-12 16:15:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1001230603327</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/labs/pmc/articles...</td>\n",
       "      <td>2021-10-12 16:19:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1001230603327</td>\n",
       "      <td></td>\n",
       "      <td>2021-10-12 16:19:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_id                                       message_data  \\\n",
       "0 -1001230603327  https://www.drugs.com/drug-interactions/sars-c...   \n",
       "1 -1001230603327  https://twitter.com/drobertalacerda/status/144...   \n",
       "2 -1001230603327  IMUNIDADE NATURAL: \\n\\nCientistas identificam ...   \n",
       "5 -1001230603327  https://www.ncbi.nlm.nih.gov/labs/pmc/articles...   \n",
       "6 -1001230603327                                                      \n",
       "\n",
       "          message_utc  \n",
       "0 2021-10-12 16:02:34  \n",
       "1 2021-10-12 16:14:59  \n",
       "2 2021-10-12 16:15:23  \n",
       "5 2021-10-12 16:19:35  \n",
       "6 2021-10-12 16:19:36  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "built_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    \"de\",\"a\",  \"o\",  \"que\",\n",
    "    \"e\",  \"do\", \"da\", \"em\",\n",
    "    \"um\", \"para\",        \"com\",\"não\",\n",
    "    \"uma\",\"os\", \"no\", \"se\",\n",
    "    \"na\", \"por\",\"mais\",        \"as\",\n",
    "    \"dos\",\"como\",        \"mas\",\"ao\",\n",
    "    \"ele\",\"das\",\"à\",  \"seu\",\n",
    "    \"sua\",\"ou\", \"quando\",      \"muito\",\n",
    "    \"nos\",\"já\", \"eu\", \"também\",\n",
    "    \"só\", \"pelo\",        \"pela\",        \"até\",\n",
    "    \"isso\",        \"ela\",\"entre\",       \"depois\",\n",
    "    \"sem\",\"mesmo\",       \"aos\",\"seus\",\n",
    "    \"quem\",        \"nas\",\"me\", \"esse\",\n",
    "    \"eles\",        \"você\",        \"essa\",        \"num\",\n",
    "    \"nem\",\"suas\",        \"meu\",\"às\",\n",
    "    \"minha\",       \"numa\",        \"pelos\",       \"elas\",\n",
    "    \"qual\",        \"nós\",\"lhe\",\"deles\",\n",
    "    \"essas\",       \"esses\",       \"pelas\",       \"este\",\n",
    "    \"dele\",        \"tu\", \"te\", \"vocês\",\n",
    "    \"vos\",\"lhes\",        \"meus\",        \"minhas\",\n",
    "    \"teu\",\"tua\",\"teus\",        \"tuas\",\n",
    "    \"nosso\",       \"nossa\",       \"nossos\",      \"nossas\",\n",
    "    \"dela\",        \"delas\",       \"esta\",        \"estes\",\n",
    "    \"estas\",       \"aquele\",      \"aquela\",      \"aqueles\",\n",
    "    \"aquelas\",     \"isto\",        \"aquilo\",      \"estou\",\n",
    "    \"está\",        \"estamos\",     \"estão\",       \"estive\",\n",
    "    \"esteve\",      \"estivemos\",   \"estiveram\",   \"estava\",\n",
    "    \"estávamos\",   \"estavam\",     \"estivera\",    \"estivéramos\",\n",
    "    \"esteja\",      \"estejamos\",   \"estejam\",     \"estivesse\",\n",
    "    \"estivéssemos\",\"estivessem\",  \"estiver\",     \"estivermos\",\n",
    "    \"estiverem\",   \"hei\",\"há\", \"havemos\",\n",
    "    \"hão\",\"houve\",       \"houvemos\",    \"houveram\",\n",
    "    \"houvera\",     \"houvéramos\",  \"haja\",        \"hajamos\",\n",
    "    \"hajam\",       \"houvesse\",    \"houvéssemos\", \"houvessem\",\n",
    "    \"houver\",      \"houvermos\",   \"houverem\",    \"houverei\",\n",
    "    \"houverá\",     \"houveremos\",  \"houverão\",    \"houveria\",\n",
    "    \"houveríamos\", \"houveriam\",   \"sou\",\"somos\",\n",
    "    \"são\",\"era\",\"éramos\",      \"eram\",\n",
    "    \"fui\",\"foi\",\"fomos\",       \"foram\",\n",
    "    \"fora\",        \"fôramos\",     \"seja\",        \"sejamos\",\n",
    "    \"sejam\",       \"fosse\",       \"fôssemos\",    \"fossem\",\n",
    "    \"for\",\"formos\",      \"forem\",       \"serei\",\n",
    "    \"será\",        \"seremos\",     \"serão\",       \"seria\",\n",
    "    \"seríamos\",    \"seriam\",      \"tenho\",       \"tem\",\n",
    "    \"temos\",       \"tém\",\"tinha\",       \"tínhamos\",\n",
    "    \"tinham\",      \"tive\",        \"teve\",        \"tivemos\",\n",
    "    \"tiveram\",     \"tivera\",      \"tivéramos\",   \"tenha\",\n",
    "    \"tenhamos\",    \"tenham\",      \"tivesse\",     \"tivéssemos\",\n",
    "    \"tivessem\",    \"tiver\",       \"tivermos\",    \"tiverem\",\n",
    "    \"terei\",       \"terá\",        \"teremos\",     \"terão\",\n",
    "    \"teria\",       \"teríamos\",    \"teriam\", \"pra\",\n",
    "    \"fala\", \"disse\", \"diz\", \"vai\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Certifique-se de que o DataFrame não está vazio\n",
    "    if not built_df.empty:\n",
    "        # Concatenar todas as mensagens em uma única string\n",
    "        all_messages = ' '.join(built_df['message_data'])\n",
    "\n",
    "        # Criar a nuvem de palavras\n",
    "        wordcloud = WordCloud(stopwords = stopword_list, \n",
    "                              normalize_plurals = False, \n",
    "                              width = 800, \n",
    "                              height = 400, \n",
    "                              background_color = 'white').generate(all_messages)\n",
    "\n",
    "        # Exibir a nuvem de palavras usando Matplotlib\n",
    "        plt.figure(figsize = (10, 5))\n",
    "        plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"O DataFrame está vazio. Nenhuma nuvem de palavras será gerada.\")\n",
    "\n",
    "except Exception as error:\n",
    "    print(\"Erro ao gerar a nuvem de palavras:\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
